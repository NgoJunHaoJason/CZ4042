{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitaivenvcondaf74d87cbcd1c41a2a9ab01eaafaa18b6",
   "display_name": "Python 3.8.3 64-bit ('ai_venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1 shows a three-layer feedforward neural network receiving 3-dimensional inputs $(x_{1}, x_{2}, x_{3}) ∈ R^{3}$. The connection weights and biases of the neurons $n_{1}$, $n_{2}$ and $n_{3}$ are as indicated in the figure. The hidden-layer neurons have activation functions given by $g(u) = \\frac{1.0}{1+e^{−0.5u}}$ where u denotes the synaptic input to the neuron. The activation function $f(u)$ of the output neuron is a ReLU function: $f(u) = max\\{0, u\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def hidden_activation(synaptic_input):\n",
    "    return 1.0 / (1 + math.e**(-0.5 * synaptic_input))\n",
    "\n",
    "\n",
    "def relu(synaptic_input):\n",
    "    return max(0, synaptic_input)\n",
    "\n",
    "\n",
    "g = lambda u: hidden_activation(u)\n",
    "f = lambda u: relu(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![figure 1](figure_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Write weight vectors and biases connected to individual neurons, and the weight matrix and bias vector connected to the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w_1 = np.array([1.0, -0.5, -1.0])\n",
    "b_1 = 0\n",
    "\n",
    "w_2 = np.array([0, 2.0, 0.6])\n",
    "b_2 = 0.5\n",
    "\n",
    "w_3 = np.array([-0.5, 0.6])\n",
    "b_3 = 0.05\n",
    "\n",
    "w_h = np.array([w_1, w_2])\n",
    "b_h = np.array([b_1, b_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the synaptic inputs and activations of the neurons for the following\n",
    "input signals:\n",
    "\n",
    "- (1.0, –0.5, 1.0)\n",
    "- (-1.0, 0.0, –2.0)\n",
    "- (2.0, 0.5, –1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self, name, weights, bias, activation):\n",
    "        self.__name = name\n",
    "        self.__weights = weights\n",
    "        self.__bias = bias\n",
    "        self.__activation = activation\n",
    "\n",
    "    def __call__(self, neuron_input):\n",
    "        synaptic_input = neuron_input @ self.__weights + self.__bias\n",
    "        print(f'synaptic input at {self.__name}: {synaptic_input:2f}')\n",
    "\n",
    "        output = self.__activation(synaptic_input)\n",
    "        print(f'activation at {self.__name}: {output:2f}')\n",
    "\n",
    "        print()\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.__n_1 = Neuron('n1', w_1, b_1, g)\n",
    "        self.__n_2 = Neuron('n2', w_2, b_2, g)\n",
    "        self.__n_3 = Neuron('n3', w_3, b_3, f)\n",
    "\n",
    "    def __call__(self, network_input):\n",
    "        n_3_input = np.array([self.__n_1(network_input), self.__n_2(network_input)])\n",
    "        return self.__n_3(n_3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "for input (1.0, -0.5, 1.0):\n\nsynaptic input at n1: 0.250000\nactivation at n1: 0.531209\n\nsynaptic input at n2: 0.100000\nactivation at n2: 0.512497\n\nsynaptic input at n3: 0.091894\nactivation at n3: 0.091894\n\noutput: 0.091894\n\nfor input (-1.0, 0.0, -2.0):\n\nsynaptic input at n1: 1.000000\nactivation at n1: 0.622459\n\nsynaptic input at n2: -0.700000\nactivation at n2: 0.413382\n\nsynaptic input at n3: -0.013200\nactivation at n3: 0.000000\n\noutput: 0.000000\n\nfor input (2.0, 0.5, -1.0):\n\nsynaptic input at n1: 2.750000\nactivation at n1: 0.798187\n\nsynaptic input at n2: 0.900000\nactivation at n2: 0.610639\n\nsynaptic input at n3: 0.017290\nactivation at n3: 0.017290\n\noutput: 0.017290\n\n"
    }
   ],
   "source": [
    "input_1 = (1.0, -0.5, 1.0)\n",
    "input_2 = (-1.0, 0.0, -2.0)\n",
    "input_3 = (2.0, 0.5, -1.0)\n",
    "\n",
    "inputs = [input_1, input_2, input_3]\n",
    "network = Network()\n",
    "\n",
    "for network_input in inputs:\n",
    "    print(f'for input {network_input}:\\n')\n",
    "\n",
    "    output = network(network_input)\n",
    "    print(f'output: {output:2f}\\n')"
   ]
  }
 ]
}