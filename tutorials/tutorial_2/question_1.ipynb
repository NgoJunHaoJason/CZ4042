{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitaivenvcondaf74d87cbcd1c41a2a9ab01eaafaa18b6",
   "display_name": "Python 3.8.3 64-bit ('ai_venv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a linear neuron to perform the following mapping:\n",
    "\n",
    "$x = (x_1, x_2, x_3)$ | $y$\n",
    "-|-\n",
    "$(0.09 −0.44 −0.15)$ | $−2.57$\n",
    "$(0.69 −0.99 −0.76)$ | $−2.97$\n",
    "$(0.34 0.65 −0.73)$ | $0.96$\n",
    "$(0.15 0.78 −0.58)$ | $1.04$\n",
    "$(−0.63 −0.78 −0.56)$ | $−3.21$\n",
    "$(0.96 0.62 −0.66)$ | $1.05$\n",
    "$(0.63 −0.45 −0.14)$ | $−2.39$\n",
    "$(0.88 0.64 −0.33)$ | $0.66$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "training_data = {\n",
    "    (0.09, -0.44, -0.15): -2.57,\n",
    "    (0.69, -0.99, -0.76): -2.97,\n",
    "    (0.34, 0.65, -0.73): 0.96,\n",
    "    (0.15, 0.78, -0.58): 1.04,\n",
    "    (-0.63, -0.78, -0.56): -3.21,\n",
    "    (0.96, 0.62, -0.66): 1.05,\n",
    "    (0.63, -0.45, -0.14): -2.39,\n",
    "    (0.88, 0.64, -0.33): 0.66,\n",
    "}\n",
    "\n",
    "\n",
    "class LinearNeuron:\n",
    "    def __init__(self, weights: tf.Variable, bias: tf.Variable):\n",
    "        '''\n",
    "        Constructs a linear neuron\n",
    "\n",
    "        :params:\n",
    "        - weights (tf.Variable): initial weights\n",
    "        - bias (tf.Variable): initial bias\n",
    "        '''\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def __call__(self, neuron_input):\n",
    "        '''\n",
    "        Get output of this neuron, from given input\n",
    "\n",
    "        :params:\n",
    "        - neuron_input: input to this neuron\n",
    "        '''\n",
    "        return tf.tensordot(neuron_input, self.weights, axes=1) + self.bias\n",
    "\n",
    "    def update_params(\n",
    "        self,\n",
    "        train_inputs,\n",
    "        train_outputs,\n",
    "        method: str = 'sgd',\n",
    "        learning_rate: float = 0.01,\n",
    "    ) -> float:\n",
    "        '''\n",
    "        One step of training\n",
    "\n",
    "        :params:\n",
    "        - train_inputs: TODO\n",
    "        - train_outputs: TODO\n",
    "        - method (str): method to use for training the neuron - 'sgd' or 'gd' (default: 'sgd')\n",
    "        - learning_rate (float): how much to learn at this step (default: 0.01)\n",
    "\n",
    "        :return:\n",
    "        - loss (mean squared error)\n",
    "        '''\n",
    "        if method == 'sgd':\n",
    "            train_data = list(zip(train_inputs, train_outputs))\n",
    "            random.shuffle(train_data)\n",
    "\n",
    "            sse = 0  # sum squared error\n",
    "\n",
    "            for train_input, train_output in train_data:\n",
    "                output = self(train_input)\n",
    "                learning_amount = learning_rate * (train_output - output)\n",
    "\n",
    "                self.weights = self.weights + learning_amount * train_input\n",
    "                self.bias = self.bias + learning_amount\n",
    "\n",
    "                squared_error = 0.5 * (train_output - output)**2\n",
    "                sse += squared_error\n",
    "\n",
    "            return sse / len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show one iteration of learning of the neuron with  \n",
    "(a) Stochastic gradient descent learning  \n",
    "(b) Gradient descent learning\n",
    "\n",
    "Initialize the weights as $\\begin{pmatrix} 0.77 \\\\ 0.02 \\\\ 0.63 \\end{pmatrix}$ and biases to $0.0$, and use a learning factor $α = 0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "before sgd - weights: [0.77 0.02 0.63], bias: 0.0\nafter sgd - weights: [0.7588135  0.11362498 0.65190977], bias: -0.07202943414449692\nloss: 1.9617705345153809\n"
    }
   ],
   "source": [
    "initial_weights = tf.Variable([0.77, 0.02, 0.63])\n",
    "initial_bias = tf.Variable(0.0)\n",
    "\n",
    "train_inputs = [\n",
    "    tf.Variable(train_input)\n",
    "    for train_input in training_data.keys()\n",
    "]\n",
    "train_outputs = [\n",
    "    tf.Variable(train_output)\n",
    "    for train_output in training_data.values()\n",
    "]\n",
    "\n",
    "# (a)\n",
    "neuron1 = LinearNeuron(initial_weights, initial_bias)\n",
    "\n",
    "tf.print(f'before sgd - weights: {neuron1.weights.numpy()}, bias: {neuron1.bias.numpy()}')\n",
    "\n",
    "loss = neuron1.update_params(train_inputs, train_outputs)\n",
    "\n",
    "print(f'after sgd - weights: {neuron1.weights.numpy()}, bias: {neuron1.bias.numpy()}')\n",
    "print(f'loss: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the learning curves (mean square error vs. epochs) until convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the learned weights, biases, and the predicted values of y by the neuron."
   ]
  }
 ]
}